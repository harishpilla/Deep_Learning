{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a56e4a2e",
      "metadata": {
        "id": "a56e4a2e"
      },
      "outputs": [],
      "source": [
        "# Import the required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import random\n",
        "from math import log\n",
        "\n",
        "import tensorflow \n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import LSTM, SimpleRNN, GRU, Embedding, Dense, TimeDistributed, Concatenate, AdditiveAttention "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install wandb and wandbcallback libraries\n",
        "%pip install wandb -q\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvElZMAcEqdg",
        "outputId": "60ec4cb0-1227-45a1-d450-68937dbaa0da"
      },
      "id": "LvElZMAcEqdg",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 52.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 45.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.font_manager import FontProperties\n",
        "from IPython.display import HTML as html_print\n",
        "import time\n",
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "Ck70W2o9Fw8P"
      },
      "id": "Ck70W2o9Fw8P",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the dataset\n"
      ],
      "metadata": {
        "id": "W0HZLliq4vAw"
      },
      "id": "W0HZLliq4vAw"
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "if not os.path.exists('/content/dakshina_dataset_v1.0.tar'):\n",
        "    !wget \"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67pDt3xkEr06",
        "outputId": "256fdccb-f5f6-4038-b9d1-699400359b38"
      },
      "id": "67pDt3xkEr06",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-07 06:27:05--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.121.128, 108.177.120.128, 142.251.6.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.121.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G   139MB/s    in 11s     \n",
            "\n",
            "2022-05-07 06:27:16 (167 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip every file\n",
        "!tar -xvf /content/dakshina_dataset_v1.0.tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPvCnsn6Etg3",
        "outputId": "323d82a8-3dc2-44ce-a6e9-6f74859bcff0"
      },
      "id": "ZPvCnsn6Etg3",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dakshina_dataset_v1.0/bn/\n",
            "dakshina_dataset_v1.0/bn/lexicons/\n",
            "dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/romanized/\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/gu/\n",
            "dakshina_dataset_v1.0/gu/lexicons/\n",
            "dakshina_dataset_v1.0/gu/lexicons/gu.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/gu/lexicons/gu.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/gu/lexicons/gu.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/romanized/\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/hi/\n",
            "dakshina_dataset_v1.0/hi/lexicons/\n",
            "dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/hi/romanized/\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/kn/\n",
            "dakshina_dataset_v1.0/kn/lexicons/\n",
            "dakshina_dataset_v1.0/kn/lexicons/kn.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/kn/lexicons/kn.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/kn/lexicons/kn.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/kn/romanized/\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/ml/\n",
            "dakshina_dataset_v1.0/ml/lexicons/\n",
            "dakshina_dataset_v1.0/ml/lexicons/ml.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/ml/lexicons/tmp.rom.txt\n",
            "dakshina_dataset_v1.0/ml/lexicons/tmp.tsv\n",
            "dakshina_dataset_v1.0/ml/lexicons/ml.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/ml/lexicons/ml.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/romanized/\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/mr/\n",
            "dakshina_dataset_v1.0/mr/lexicons/\n",
            "dakshina_dataset_v1.0/mr/lexicons/mr.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/mr/lexicons/mr.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/mr/lexicons/mr.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/romanized/\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/pa/\n",
            "dakshina_dataset_v1.0/pa/lexicons/\n",
            "dakshina_dataset_v1.0/pa/lexicons/pa.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/pa/lexicons/pa.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/pa/lexicons/pa.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/pa/romanized/\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/sd/\n",
            "dakshina_dataset_v1.0/sd/lexicons/\n",
            "dakshina_dataset_v1.0/sd/lexicons/sd.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/sd/lexicons/sd.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/sd/lexicons/sd.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/sd/romanized/\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/si/\n",
            "dakshina_dataset_v1.0/si/lexicons/\n",
            "dakshina_dataset_v1.0/si/lexicons/si.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/si/lexicons/si.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/si/lexicons/si.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/si/romanized/\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/ta/\n",
            "dakshina_dataset_v1.0/ta/lexicons/\n",
            "dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/romanized/\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/te/\n",
            "dakshina_dataset_v1.0/te/lexicons/\n",
            "dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/te/romanized/\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/ur/\n",
            "dakshina_dataset_v1.0/ur/lexicons/\n",
            "dakshina_dataset_v1.0/ur/lexicons/ur.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/ur/lexicons/ur.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/ur/lexicons/ur.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/romanized/\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the training dataset file\n",
        "train_file = open(\"/content/dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.train.tsv\")\n",
        "read_train_file = csv.reader(train_file, delimiter=\"\\t\")\n",
        "\n",
        "# Load the validation dataset file\n",
        "val_file = open(\"/content/dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.dev.tsv\")\n",
        "read_val_file = csv.reader(val_file, delimiter=\"\\t\")\n",
        "\n",
        "# Load the test dataset file\n",
        "test_file = open(\"/content/dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.test.tsv\")\n",
        "read_test_file = csv.reader(test_file, delimiter=\"\\t\")\n",
        "\n",
        "# Path to save the predictions file\n",
        "predictions_path = 'predictions.tsv'"
      ],
      "metadata": {
        "id": "QyyeiUwvEvS7"
      },
      "id": "QyyeiUwvEvS7",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess and Encode Data"
      ],
      "metadata": {
        "id": "ZckeDDQeH8Bk"
      },
      "id": "ZckeDDQeH8Bk"
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all the input words(English) and target words(Telugu) in Training dataset\n",
        "telugu_words = []\n",
        "english_words = []\n",
        "\n",
        "for i in read_train_file:   \n",
        "    telugu_words.append(\"\\t\" + str(i[0]) + \"\\n\")\n",
        "    english_words.append(str(i[1]))\n",
        "\n",
        "# Get all the input words(English) and target words(Telugu) in Validation dataset\n",
        "val_telugu_words = []\n",
        "val_english_words = []\n",
        "\n",
        "for i in read_val_file:\n",
        "    val_telugu_words.append(\"\\t\" + str(i[0]) + \"\\n\")\n",
        "    val_english_words.append(str(i[1]))\n",
        "\n",
        "\n",
        "# Get all the input words(English) and target words(Telugu) in Test dataset\n",
        "test_telugu_words = []\n",
        "test_english_words = []\n",
        "\n",
        "for i in read_test_file:\n",
        "    test_telugu_words.append(\"\\t\" + str(i[0]) + \"\\n\")\n",
        "    test_english_words.append(str(i[1]))\n"
      ],
      "metadata": {
        "id": "uVFcA9-RE1Qx"
      },
      "id": "uVFcA9-RE1Qx",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the total list of input words(English)\n",
        "total_input_words = english_words + val_english_words + test_english_words\n",
        "\n",
        "# Get the total list of target words(Telugu)\n",
        "total_output_words = telugu_words + val_telugu_words + test_telugu_words"
      ],
      "metadata": {
        "id": "TxFzi3gtE2uJ"
      },
      "id": "TxFzi3gtE2uJ",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the total input and target language characters \n",
        "\n",
        "english_characters = set()\n",
        "english_characters.add(\" \")\n",
        "telugu_characters = set()\n",
        "telugu_characters.add(\" \")\n",
        "\n",
        "for word in total_input_words:\n",
        "    for char in word:\n",
        "        if char not in english_characters:\n",
        "            english_characters.add(char)\n",
        "\n",
        "for word in total_output_words:\n",
        "    for char in word:\n",
        "        if char not in telugu_characters:\n",
        "            telugu_characters.add(char)"
      ],
      "metadata": {
        "id": "iINDSGHJE4b2"
      },
      "id": "iINDSGHJE4b2",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the list of input characters(English) and target characters(Telugu)\n",
        "english_characters = sorted(list(english_characters))\n",
        "telugu_characters = sorted(list(telugu_characters))\n",
        "\n",
        "# Get total number of characters in Input \n",
        "num_encoder_tokens = len(english_characters)\n",
        "# Get total number of characters in Output \n",
        "num_decoder_tokens = len(telugu_characters)\n",
        "\n",
        "# Get maximum length of the word in total input words\n",
        "max_encoder_seq_length = max([len(text) for text in total_input_words])\n",
        "# Get maximum length of the word in total target words\n",
        "max_decoder_seq_length = max([len(text) for text in total_output_words])\n",
        "\n",
        "print(\"Summary of the dataset :\")\n",
        "print(\"Number of train samples :\" , len(english_words))\n",
        "print(\"Number of val samples :\" , len(val_english_words))\n",
        "print(\"Number of test samples :\" , len(test_english_words))\n",
        "print(\"Number of unique input tokens :\" , num_encoder_tokens)\n",
        "print(\"Number of unique output tokens :\" , num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\" , max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\" , max_decoder_seq_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myI3PSgCE56-",
        "outputId": "5283d0e5-6467-42d8-cd12-d926d8e730d6"
      },
      "id": "myI3PSgCE56-",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary of the dataset :\n",
            "Number of train samples : 58550\n",
            "Number of val samples : 5683\n",
            "Number of test samples : 5747\n",
            "Number of unique input tokens : 27\n",
            "Number of unique output tokens : 66\n",
            "Max sequence length for inputs: 25\n",
            "Max sequence length for outputs: 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary for every english character with an index associated to it\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(english_characters)])\n",
        "# Dictionary for every telugu character with an index associated to it\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(telugu_characters)])\n",
        "\n",
        "# Dictionary for every english character with an index associated to it\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "# Dictionary for every english character with an index associated to it\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "\n",
        "# Preparing train encoder and decoder inputs and decoder target\n",
        "encoder_input_data = np.zeros((len(english_words), max_encoder_seq_length), dtype=\"float32\")\n",
        "decoder_input_data = np.zeros((len(english_words), max_decoder_seq_length), dtype=\"float32\")\n",
        "decoder_target_data = np.zeros((len(english_words), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
        "\n",
        "# Writing the encoder , decoder characters with the indexes in input and target token index \n",
        "for i, (english, telugu) in enumerate(zip(english_words, telugu_words)):\n",
        "    for t, char in enumerate(english):\n",
        "        encoder_input_data[i, t] = input_token_index[char]\n",
        "    \n",
        "    for t, char in enumerate(telugu):\n",
        "        decoder_input_data[i, t] = target_token_index[char]\n",
        "        if t > 0:\n",
        "            # One got encoding the decoder_target_data  and decoder_target_data will be ahead by one timestep and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0    \n",
        "    decoder_input_data[i, t+1:] = target_token_index[' ']\n",
        "    decoder_target_data[i, t :, target_token_index[' ']] = 1.0"
      ],
      "metadata": {
        "id": "0Td6oWd5E7BS"
      },
      "id": "0Td6oWd5E7BS",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing validation encoder and decoder inputs\n",
        "\n",
        "encoder_val_input_data = np.zeros((len(val_english_words), max_encoder_seq_length), dtype=\"float32\")\n",
        "decoder_val_input_data = np.zeros((len(val_english_words), max_decoder_seq_length), dtype=\"float32\")\n",
        "decoder_val_target_data = np.zeros((len(val_english_words), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
        "\n",
        "for i, (english, telugu) in enumerate(zip(val_english_words, val_telugu_words)):\n",
        "    for t, char in enumerate(english):\n",
        "        encoder_val_input_data[i, t] = input_token_index[char]\n",
        "  \n",
        "    for t, char in enumerate(telugu):\n",
        "        decoder_val_input_data[i, t] =  target_token_index[char]\n",
        "        if t > 0:\n",
        "            # One got encoding the validation decoder target data  and validation decoder target data will be ahead by one timestep and will not include the start character.\n",
        "            decoder_val_target_data[i, t - 1, target_token_index[char]] = 1.0   \n",
        "    decoder_val_input_data[i, t+1:] = target_token_index[' ']\n",
        "    decoder_val_target_data[i, t :, target_token_index[' ']] = 1.0"
      ],
      "metadata": {
        "id": "ieQIs1mHE9IB"
      },
      "id": "ieQIs1mHE9IB",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing test encoder and decoder inputs\n",
        "\n",
        "encoder_test_input_data = np.zeros((len(test_english_words), max_encoder_seq_length), dtype=\"float32\")\n",
        "decoder_test_input_data = np.zeros((len(test_english_words), max_decoder_seq_length), dtype=\"float32\")\n",
        "decoder_test_target_data = np.zeros((len(test_english_words), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
        "\n",
        "for i, (english, telugu) in enumerate(zip(test_english_words, test_telugu_words)):\n",
        "    for t, char in enumerate(english):\n",
        "        encoder_test_input_data[i, t] = input_token_index[char]\n",
        "  \n",
        "    for t, char in enumerate(telugu):\n",
        "        decoder_test_input_data[i, t] =  target_token_index[char]\n",
        "        if t > 0:\n",
        "            # One got encoding the validation decoder target data  and validation decoder target data will be ahead by one timestep and will not include the start character.\n",
        "            decoder_test_target_data[i, t - 1, target_token_index[char]] = 1.0   \n",
        "    decoder_test_input_data[i, t+1:] = target_token_index[' ']\n",
        "    decoder_test_target_data[i, t :, target_token_index[' ']] = 1.0"
      ],
      "metadata": {
        "id": "3klNgsNnvh7H"
      },
      "id": "3klNgsNnvh7H",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the validation telugu and english words to numpy arrays\n",
        "val_telugu_words = np.array(val_telugu_words)\n",
        "val_english_words = np.array(val_english_words)\n",
        "\n",
        "# Converting the test telugu and english words to numpy arrays\n",
        "test_telugu_words = np.array(test_telugu_words)\n",
        "test_english_words = np.array(test_english_words)"
      ],
      "metadata": {
        "id": "JGtZsL7mE-u7"
      },
      "id": "JGtZsL7mE-u7",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(predictions_path, 'w') as f:\n",
        "        f.write('Input English Words, Predicted Telugu Words, Actual Telugu Words\\n')"
      ],
      "metadata": {
        "id": "wSStbTSH0c4e"
      },
      "id": "wSStbTSH0c4e",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Build Model"
      ],
      "metadata": {
        "id": "_7Wfd-zjIDZ8"
      },
      "id": "_7Wfd-zjIDZ8"
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomRNN(object):\n",
        "    \n",
        "    def __init__(self, input_embedding_size, cell_type='GRU', hidden_layer_size=32,\n",
        "                 num_encoder_layers=2, num_decoder_layers = 2, dropout=0.1, \n",
        "                 batch_size=32, epochs=25, is_test_model=False):\n",
        "\n",
        "        self.cell_type = cell_type\n",
        "        self.input_embedding_size = input_embedding_size\n",
        "        self.cell_type = cell_type\n",
        "        self.hidden_layer_size = hidden_layer_size\n",
        "        self.num_encoder_layers = num_encoder_layers\n",
        "        self.num_decoder_layers = num_decoder_layers\n",
        "        self.dropout = dropout\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.is_test_model = is_test_model\n",
        "\n",
        "\n",
        "    def training(self):\n",
        "        \"\"\"\n",
        "        Method to train the model using LSTM or GRU or RNN and\n",
        "        return model along with encoder_layers and decoder_layers.\n",
        "        \"\"\"\n",
        "\n",
        "        # Choose customFunction based on cell_type\n",
        "        customFunction = None\n",
        "        if self.cell_type == 'LSTM':\n",
        "            customFunction = LSTM\n",
        "        elif self.cell_type == 'GRU':\n",
        "            customFunction = GRU\n",
        "        elif self.cell_type == 'RNN':\n",
        "            customFunction = SimpleRNN\n",
        "\n",
        "        # Encoders\n",
        "        encoder_inputs = Input(shape=(None,))\n",
        "        encoder_embedding = Embedding(num_encoder_tokens,self.input_embedding_size, input_length = max_encoder_seq_length)(encoder_inputs)\n",
        "        \n",
        "        # get encoder_layers and encoder_states\n",
        "        encoder_layers = []\n",
        "        encoder_states = []    \n",
        "        if self.cell_type == 'LSTM':\n",
        "            encoder = customFunction(self.hidden_layer_size, return_sequences=True, return_state=True, dropout = self.dropout)\n",
        "            encoder_layers.append(encoder)\n",
        "            encoder_outputs, state_h, state_c = encoder(encoder_embedding)\n",
        "            encoder_states.append([state_h, state_c])\n",
        "\n",
        "            for i in range(1,self.num_encoder_layers):\n",
        "                encoder = customFunction(self.hidden_layer_size,return_sequences=True,return_state=True, dropout = self.dropout) \n",
        "                encoder_layers.append(encoder)\n",
        "                encoder_outputs, state_h, state_c = encoder(encoder_outputs)\n",
        "                encoder_states.append([state_h, state_c])\n",
        "        else:\n",
        "            encoder = customFunction(self.hidden_layer_size, return_sequences=True, return_state=True, dropout = self.dropout)\n",
        "            encoder_layers.append(encoder)\n",
        "            encoder_outputs, state_h = encoder(encoder_embedding)\n",
        "            encoder_states.append([state_h])\n",
        "\n",
        "            for i in range(1,self.num_encoder_layers):\n",
        "                encoder = customFunction(self.hidden_layer_size,return_sequences=True,return_state=True, dropout = self.dropout) \n",
        "                encoder_layers.append(encoder)\n",
        "                encoder_outputs, state_h = encoder(encoder_outputs)\n",
        "                encoder_states.append([state_h])\n",
        "        \n",
        "        # Decoders\n",
        "        decoder_inputs = Input(shape=(None,))\n",
        "        decoder_embedding = Embedding(num_decoder_tokens,self.input_embedding_size, input_length = max_decoder_seq_length)(decoder_inputs)\n",
        "\n",
        "        # get decoder_layers\n",
        "        decoder_layers = []\n",
        "        if self.cell_type == 'LSTM':\n",
        "            decoder_lstm = customFunction(self.hidden_layer_size, return_sequences=True, return_state=True, dropout = self.dropout)\n",
        "            decoder_layers.append(decoder_lstm)\n",
        "            decoder_outputs, _ , _ = decoder_lstm(decoder_embedding, initial_state=encoder_states[0])\n",
        "            for i in range(1,self.num_decoder_layers):\n",
        "                decoder_lstm = customFunction(self.hidden_layer_size, return_sequences=True, return_state=True, dropout = self.dropout)\n",
        "                decoder_layers.append(decoder_lstm)\n",
        "                decoder_outputs, _ , _  = decoder_lstm(decoder_outputs, initial_state=encoder_states[i])\n",
        "        else:\n",
        "            decoder_GRU = customFunction(self.hidden_layer_size, return_sequences=True, return_state=True, dropout = self.dropout)\n",
        "            decoder_layers.append(decoder_GRU)\n",
        "            decoder_outputs, _ = decoder_GRU(decoder_embedding, initial_state=encoder_states[0])\n",
        "            for i in range(1,self.num_decoder_layers):\n",
        "                decoder_GRU = customFunction(self.hidden_layer_size, return_sequences=True, return_state=True, dropout = self.dropout)\n",
        "                decoder_layers.append(decoder_GRU)\n",
        "                decoder_outputs, _  = decoder_GRU(decoder_outputs, initial_state=encoder_states[i])\n",
        "\n",
        "        # Add decoder attention layer\n",
        "        decoder_attention = AdditiveAttention(name=\"decoder_attention\")\n",
        "        decoder_concat = Concatenate(name=\"decoder_concat\")\n",
        "        context_vector, _ = decoder_attention([decoder_outputs, encoder_outputs], return_attention_scores=True)\n",
        "        decoder_outputs = decoder_concat([decoder_outputs, context_vector])\n",
        "        \n",
        "        # Add dense layer to decoder\n",
        "        decoder_dense = Dense(num_decoder_tokens, activation=\"softmax\")\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "        # Create a model, compile and fit the model using the optimizer.\n",
        "        model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "        model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "        # If test_model, do not add wandb callback\n",
        "        if self.is_test_model:\n",
        "            model.fit(\n",
        "                [encoder_input_data, decoder_input_data],\n",
        "                decoder_target_data,\n",
        "                batch_size=self.batch_size,\n",
        "                epochs=self.epochs\n",
        "            )\n",
        "        else:\n",
        "            model.fit(\n",
        "                [encoder_input_data, decoder_input_data],\n",
        "                decoder_target_data,\n",
        "                batch_size=self.batch_size,\n",
        "                epochs=self.epochs,\n",
        "                callbacks=[WandbCallback()]\n",
        "            )\n",
        "\n",
        "        return model, encoder_layers, decoder_layers\n",
        "\n",
        "\n",
        "    def inference_model(self, model, encoder_layers, decoder_layers):\n",
        "        \"\"\"\n",
        "        Create the encoder_model, decoder_model and return using the\n",
        "        arguments model, encoder_layers and decoder_layers\n",
        "        \"\"\"\n",
        "        \n",
        "        # generate encoder_model \n",
        "        encoder_inputs = model.input[0]  # input_1\n",
        "        encoder_states = []\n",
        "        enc_emb = model.layers[2]     # embedding 1\n",
        "        encoder_outputs = enc_emb(encoder_inputs)\n",
        "\n",
        "        if self.cell_type == 'RNN' or self.cell_type ==\"GRU\":\n",
        "            for i in range(self.num_encoder_layers):\n",
        "                encoder_outputs, state_h_enc = encoder_layers[i](encoder_outputs)\n",
        "                encoder_states += [state_h_enc] \n",
        "        else:\n",
        "            for i in range(self.num_encoder_layers):\n",
        "                encoder_outputs, state_h_enc, state_c_enc = encoder_layers[i](encoder_outputs)\n",
        "                encoder_states += [state_h_enc, state_c_enc]   \n",
        "\n",
        "        encoder_model = Model(encoder_inputs, encoder_states + [encoder_outputs])\n",
        "\n",
        "\n",
        "        # generate decoder_model\n",
        "        input_names = [[\"input_100\",\"input_101\"],[\"input_102\",\"input_103\"],[\"input_104\",\"input_105\"],\"input_106\"]\n",
        "\n",
        "        decoder_inputs = model.input[1]       # input_2\n",
        "        decoder_embedding = model.layers[3]   # embedding 2\n",
        "        decoder_outputs = decoder_embedding(decoder_inputs)\n",
        "        decoder_states = []\n",
        "        decoder_states_inputs = []\n",
        "        \n",
        "        if self.cell_type == 'RNN' or self.cell_type ==\"GRU\":\n",
        "            for i in range(self.num_decoder_layers):\n",
        "                decoder_states_inputs += [Input(shape=(self.hidden_layer_size,), name=input_names[i][0])]\n",
        "            for i in range(self.num_decoder_layers):\n",
        "                decoder_outputs, state_h_dec = decoder_layers[i](decoder_outputs, initial_state=decoder_states_inputs[i])\n",
        "                decoder_states += [state_h_dec]\n",
        "        else:\n",
        "            for i in range(self.num_decoder_layers):\n",
        "                decoder_states_inputs += [Input(shape=(self.hidden_layer_size,), name=input_names[i][0]), Input(shape=(self.hidden_layer_size,), name=input_names[i][1])]\n",
        "            j = 0\n",
        "            for i in range(self.num_decoder_layers):\n",
        "                decoder_outputs, state_h_dec, state_c_dec = decoder_layers[i](decoder_outputs, initial_state=decoder_states_inputs[i+j:i+j+2])\n",
        "                decoder_states += [state_h_dec , state_c_dec]\n",
        "                j += 1\n",
        "\n",
        "        attention_layer = model.layers[4+2*self.num_encoder_layers]\n",
        "        attention_input = Input(shape=(max_encoder_seq_length,self.hidden_layer_size), name=input_names[-1])   \n",
        "        context_vec, attention_weights = attention_layer([decoder_outputs, attention_input], return_attention_scores=True)\n",
        "        \n",
        "        concat_layer = model.layers[5+2*self.num_encoder_layers]\n",
        "        decoder_outputs = concat_layer([decoder_outputs, context_vec])\n",
        "\n",
        "        decoder_dense = model.layers[6+2*self.num_encoder_layers]\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "        decoder_model = Model([decoder_inputs] + decoder_states_inputs + [attention_input], [decoder_outputs] + decoder_states + [attention_weights])\n",
        "\n",
        "        return encoder_model, decoder_model\n",
        "\n",
        "\n",
        "    def decode_sequence(self, input_seq, encoder_model, decoder_model):\n",
        "        \"\"\"\n",
        "        Method to decode an input sequence using the encoder_model\n",
        "        and decoder_model\n",
        "        \"\"\"\n",
        "        states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "        # get attention input\n",
        "        attention_input = states_value[-1]\n",
        "        states_value = states_value[:-1]\n",
        "        target_seq = np.zeros((1, 1)) \n",
        "        target_seq[0, 0] = target_token_index[\"\\t\"]\n",
        "        attention_weights = []\n",
        "\n",
        "        # continue decoding input sequence till '\\n' is found or the sequence\n",
        "        # exceeds the maximum decoder sequence length.\n",
        "        stop_condition = False\n",
        "        decoded_sentence = \"\"\n",
        "        while not stop_condition:\n",
        "            output_tokens = decoder_model.predict([target_seq] + states_value + [attention_input])\n",
        "            sampled_token_index = np.argmax(output_tokens[0][0, -1, :])\n",
        "            sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "            decoded_sentence += sampled_char\n",
        "            if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
        "                stop_condition = True\n",
        "\n",
        "            target_seq = np.zeros((1, 1))\n",
        "            target_seq[0, 0] = sampled_token_index\n",
        "            states_value = output_tokens[1:-1]\n",
        "            attention_weights.append(output_tokens[-1][0][0])\n",
        "            \n",
        "        return decoded_sentence, attention_weights\n",
        "\n",
        "    \n",
        "    def test_and_calculate_accuraccy(self, encoder_model, decoder_model, tmp_english_words, \n",
        "                                     tmp_telugu_words, tmp_encoder_input_data, is_val_accuracy=True):\n",
        "        \"\"\"\n",
        "        Calculate accuracy using the data and write it to prediction file.\n",
        "        \"\"\"\n",
        "        correct = 0\n",
        "        n = tmp_telugu_words.shape[0]\n",
        "        for i in range(n):\n",
        "            input = tmp_encoder_input_data[i:i+1]\n",
        "            output, _ = self.decode_sequence(input,encoder_model, decoder_model)\n",
        "            with open(predictions_path, 'a') as f:\n",
        "                    f.write('{} , {} , {}\\n'.format(tmp_english_words[i].strip(), output.strip(), tmp_telugu_words[i].strip()))\n",
        "            if output.strip() == tmp_telugu_words[i].strip():\n",
        "                correct += 1\n",
        "\n",
        "        # log accuracy to wandb\n",
        "        if is_val_accuracy:\n",
        "            wandb.log({'val_accuracy' : correct*100/n})\n",
        "            print('val_accuracy', correct*100/n)\n",
        "        else:\n",
        "            wandb.log({'test_accuracy' : correct*100/n})\n",
        "            print('test_accuracy', correct*100/n)\n",
        "\n"
      ],
      "metadata": {
        "id": "7DHTqx6sFBvQ"
      },
      "id": "7DHTqx6sFBvQ",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sweep config"
      ],
      "metadata": {
        "id": "UPwcSFfOISi7"
      },
      "id": "UPwcSFfOISi7"
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes',\n",
        "    'metric':\n",
        "    {\n",
        "        'goal': 'maximize',\n",
        "        'name': 'val_accuracy'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'input_embedding_size':\n",
        "        {\n",
        "            'values': [128, 256, 512]\n",
        "        },\n",
        "        'hidden_layer_size':\n",
        "        {\n",
        "            'values': [128, 256, 512]\n",
        "        },\n",
        "        'cell_type':\n",
        "        {\n",
        "            'values': ['LSTM', 'RNN', 'GRU']\n",
        "        },\n",
        "        'num_layers':\n",
        "        {\n",
        "            'values': [1, 2, 3]\n",
        "        },\n",
        "        'batch_size':\n",
        "        {\n",
        "            'values': [128, 256, 512]\n",
        "        },\n",
        "        'dropout':\n",
        "        {\n",
        "            'values': [0.1]\n",
        "        },\n",
        "        'epochs':\n",
        "        {\n",
        "            'values': [25]\n",
        "        }\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "vizw0Nx5GQJY"
      },
      "id": "vizw0Nx5GQJY",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_config, entity=\"cs21m010-cs21m041\", project=\"DL_Assignment_3_b\")"
      ],
      "metadata": {
        "id": "f424NbphGTFI"
      },
      "id": "f424NbphGTFI",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "\n",
        "    # Create a new WandB run\n",
        "    wandb.init(config=sweep_config)\n",
        "    \n",
        "    # Construct the run name\n",
        "    config = wandb.config\n",
        "    wandb.run.name = 'ATT_' + config.cell_type + '' + str(config.input_embedding_size) + '_hs' + str(config.hidden_layer_size) + 'bs' + str(config.batch_size)\n",
        "    \n",
        "    print('training...')\n",
        "    model_rnn_obj = CustomRNN(config.input_embedding_size, config.cell_type , config.hidden_layer_size, \n",
        "                              config.num_layers, config.num_layers, config.dropout, config.batch_size, config.epochs)\n",
        "    model, encoder_layers, decoder_layers = model_rnn_obj.training()    \n",
        "\n",
        "    print('inferrencing...')\n",
        "    encoder_model, decoder_model = model_rnn_obj.inference_model(model, encoder_layers, decoder_layers)\n",
        "    \n",
        "    print('decoding sequence...')\n",
        "    model_rnn_obj.test_and_calculate_accuraccy(encoder_model, decoder_model, val_english_words, val_telugu_words, encoder_val_input_data)"
      ],
      "metadata": {
        "id": "lZ82zKS5GU_2"
      },
      "id": "lZ82zKS5GU_2",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, train, count = 15)"
      ],
      "metadata": {
        "id": "Dnw09xJ3GZtV"
      },
      "id": "Dnw09xJ3GZtV",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fitting the Best Model"
      ],
      "metadata": {
        "id": "JhdMWLqfr_26"
      },
      "id": "JhdMWLqfr_26"
    },
    {
      "cell_type": "code",
      "source": [
        "best_sweep_config = {\n",
        "    'method': 'random',\n",
        "    'metric':\n",
        "    {\n",
        "        'goal': 'maximize',\n",
        "        'name': 'val_accuracy'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'input_embedding_size':\n",
        "        {\n",
        "            'values': [128]\n",
        "        },\n",
        "        'hidden_layer_size':\n",
        "        {\n",
        "            'values': [512]\n",
        "        },\n",
        "        'cell_type':\n",
        "        {\n",
        "            'values': ['GRU']\n",
        "        },\n",
        "        'num_layers':\n",
        "        {\n",
        "            'values': [1]\n",
        "        },\n",
        "        'batch_size':\n",
        "        {\n",
        "            'values': [128]\n",
        "        },\n",
        "        'dropout':\n",
        "        {\n",
        "            'values': [0.1]\n",
        "        },\n",
        "        'epochs':\n",
        "        {\n",
        "            'values': [25]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "7HYxvObhGEr7"
      },
      "id": "7HYxvObhGEr7",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(best_sweep_config, entity=\"cs21m010-cs21m041\", project=\"DL_Assignment_3_b\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lpqa3h7AGHR4",
        "outputId": "a3d9053f-8f54-46a4-c18c-81dfafc6f12a"
      },
      "id": "Lpqa3h7AGHR4",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: 460y1xof\n",
            "Sweep URL: https://wandb.ai/cs21m010-cs21m041/DL_Assignment_3_b/sweeps/460y1xof\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx_mo7qpU8h5",
        "outputId": "8edc1afd-6586-47df-e9b1-f7caef4a389e"
      },
      "id": "Kx_mo7qpU8h5",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize using the heatmap\n",
        "def visualize_heatmap(input_words, prediction_words, attention_weights):\n",
        "    figures = []\n",
        "    n = 9 \n",
        "    figures , axs = plt.subplots(3,3)\n",
        "    figures.set_size_inches(23, 15)\n",
        "    l = -1\n",
        "\n",
        "    k = 0\n",
        "    for i in range(n):\n",
        "        output = prediction_words[i]\n",
        "        attn_weights = attention_weights[i]\n",
        "        ylabel = [\"\"]\n",
        "        m = len(attn_weights)\n",
        "\n",
        "        chars_ = [x for x in output]\n",
        "        xlabel = [\"\"]\n",
        "        ylabel += chars_\n",
        "        xlabel += [char for char in input_words[i]]\n",
        "        \n",
        "        for j in range(m):\n",
        "            attn_weights[j] = attn_weights[j][1:len(xlabel)]\n",
        "            \n",
        "        attn_weights = attn_weights[:-1]\n",
        "        if i%3 == 0:\n",
        "            l+=1\n",
        "            k=0\n",
        "            \n",
        "        cax = axs[l][k].matshow(np.array(attn_weights))\n",
        "        axs[l][k].set_xticklabels(xlabel)\n",
        "        fontProps = FontProperties(fname = \"/content/drive/MyDrive/fonts/nirmala.ttf\")\n",
        "        axs[l][k].set_yticklabels(ylabel, fontproperties=fontProps)\n",
        "        k+=1\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ARmAXimDI4Kf"
      },
      "id": "ARmAXimDI4Kf",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Consider Best configuration\n",
        "def consider_best_model():\n",
        "    \n",
        "    # Create a new WandB run\n",
        "    wandb.init(config=best_sweep_config)\n",
        "    \n",
        "    # Construct the run name\n",
        "    config = wandb.config\n",
        "    wandb.run.name = 'ATT_Best_' + config.cell_type + '' + str(config.input_embedding_size) + '_hs' + str(config.hidden_layer_size) + 'bs' + str(config.batch_size)\n",
        "    \n",
        "    # Taking Best configuration\n",
        "    print('training...')\n",
        "    best_model_obj = CustomRNN(config.input_embedding_size, config.cell_type , config.hidden_layer_size, \n",
        "              config.num_layers, config.num_layers, config.dropout, \n",
        "              config.batch_size, config.epochs, is_test_model=True)\n",
        "    model, encoder_layers, decoder_layers = best_model_obj.training()\n",
        "\n",
        "    print('inferrencing...')\n",
        "    encoder_model, decoder_model = best_model_obj.inference_model(model, encoder_layers, decoder_layers)\n",
        "\n",
        "    print('calculating test accuracy and decoding test inputs...')\n",
        "    best_model_obj.test_and_calculate_accuraccy(encoder_model, decoder_model, test_english_words, \n",
        "                                              test_telugu_words, encoder_test_input_data, is_val_accuracy=False)\n",
        "    \n",
        "\n",
        "    indexes = [700, 994, 1070, 1111, 1206, 1441, 1691, 1977, 2535]\n",
        "    inputs = []\n",
        "    predictions = []\n",
        "    attentions = []\n",
        "\n",
        "    for i in indexes:\n",
        "        input = encoder_test_input_data[i:i+1]\n",
        "        inputs.append(test_english_words[i].strip())\n",
        "        output, attention_weights = best_model_obj.decode_sequence(input, encoder_model, decoder_model)\n",
        "        predictions.append(output.strip())\n",
        "        attentions.append(attention_weights)\n",
        "\n",
        "    visualize_heatmap(inputs, predictions, attentions)\n"
      ],
      "metadata": {
        "id": "MamcGqFxL9j8"
      },
      "id": "MamcGqFxL9j8",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, consider_best_model, count=1)"
      ],
      "metadata": {
        "id": "nUEGjhqeG3Y0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932,
          "referenced_widgets": [
            "be97848f842d4cbbb0bf067ba26740b9",
            "0abcf482c0f24642a69e3e377916dcc1",
            "da4000d236c34a66a123ea8241308e1a",
            "62c344652e5448479e0e2e01a9b4dcf1",
            "a173c5753ace4e6894fa106f8d92f90b",
            "fbfba78ae1dc4d2cb9fc2fb1c8c27196",
            "549d3d7e55a64ee9891304accdb5dd65",
            "0232b5a890c64acebd307455eaf37851"
          ]
        },
        "outputId": "035fc1b7-5b4f-4399-d937-080ee5256fcf"
      },
      "id": "nUEGjhqeG3Y0",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ai5jfens with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embedding_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220507_072739-ai5jfens</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/cs21m010-cs21m041/DL_Assignment_3_b/runs/ai5jfens\" target=\"_blank\">glad-sweep-9</a></strong> to <a href=\"https://wandb.ai/cs21m010-cs21m041/DL_Assignment_3_b\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21m010-cs21m041/DL_Assignment_3_b/sweeps/460y1xof\" target=\"_blank\">https://wandb.ai/cs21m010-cs21m041/DL_Assignment_3_b/sweeps/460y1xof</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training...\n",
            "458/458 [==============================] - 53s 107ms/step - loss: 1.1730 - accuracy: 0.6880\n",
            "inferrencing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1656x1080 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be97848f842d4cbbb0bf067ba26740b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">glad-sweep-9</strong>: <a href=\"https://wandb.ai/cs21m010-cs21m041/DL_Assignment_3_b/runs/ai5jfens\" target=\"_blank\">https://wandb.ai/cs21m010-cs21m041/DL_Assignment_3_b/runs/ai5jfens</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220507_072739-ai5jfens/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "assignment_3_part_b.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "be97848f842d4cbbb0bf067ba26740b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0abcf482c0f24642a69e3e377916dcc1",
              "IPY_MODEL_da4000d236c34a66a123ea8241308e1a"
            ],
            "layout": "IPY_MODEL_62c344652e5448479e0e2e01a9b4dcf1"
          }
        },
        "0abcf482c0f24642a69e3e377916dcc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a173c5753ace4e6894fa106f8d92f90b",
            "placeholder": "​",
            "style": "IPY_MODEL_fbfba78ae1dc4d2cb9fc2fb1c8c27196",
            "value": "0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "da4000d236c34a66a123ea8241308e1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_549d3d7e55a64ee9891304accdb5dd65",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0232b5a890c64acebd307455eaf37851",
            "value": 1
          }
        },
        "62c344652e5448479e0e2e01a9b4dcf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a173c5753ace4e6894fa106f8d92f90b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbfba78ae1dc4d2cb9fc2fb1c8c27196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "549d3d7e55a64ee9891304accdb5dd65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0232b5a890c64acebd307455eaf37851": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}